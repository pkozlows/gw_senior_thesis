\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage[version=4]{mhchem}
\usepackage{stmaryrd}
\usepackage{graphicx}
\usepackage{physics}


\usepackage{listings} % Required for insertion of code
\usepackage{xcolor} % Required for custom colors

% Define custom colors
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

% Setup the style for code listings
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

% Activate the style
\lstset{style=mystyle}



\title{Ch/ChE 164 Winter 2024 
 Homework Problem Set \#6 }

\author{}
\date{}


\begin{document}
\maketitle
Due Date: Thursday, February 29, 2024 @ 11:59pm PT

Out of 100 Points
\section{}
\section*{Project - Work on Question 1}
\begin{enumerate}
  \item Consider a liquid at temperature $T$ in equilibrium with its vapor (at pressure $p$ ). Assume that the liquid-vapor interface is planar and that the vapor can be regarded as ideal.
\end{enumerate}
\subsection{}
(i) (20 points) Use the Maxwell-Boltzmann distribution to find the average number of vapor molecules that hit the interface per unit area per unit time.\\
The distributio is given by:
\begin{equation}
f(\textbf{v}) \dd{\textbf{v}} = \left(\frac{m}{2\pi k T}\right)^{3/2} \exp\left(-\frac{m |\textbf{v}|^2}{2 k T}\right) \dd{\textbf{v}}
\end{equation}
where $m$ is the mass of the molecule, $k$ is the Boltzmann constant, and $T$ is the temperature.
We know that $|\textbf{v}|^2 = v_x^2 + v_y^2 + v_z^2$.
We are interested in the slugs to through and interface, so we want to consider the expectation value of the speed in the z direction.
\begin{equation}
\langle v_z \rangle = \left(\frac{m}{2\pi k T}\right)^{3/2} \int_{-\infty}^{\infty} \exp\left(-\frac{m v_x^2}{2 k T}\right) \dd{v_x} \int_{-\infty}^{\infty} \exp\left(-\frac{m v_y^2}{2 k T}\right) \dd{v_y} \int_{-\infty}^{\infty} v_z \exp\left(-\frac{m v_z^2}{2 k T}\right) \dd{v_z}
\end{equation}
The first two integrals are just cations that each evaluate to $\sqrt{2\pi k T/m}$, so we are left with:
\begin{equation}
\langle v_z \rangle = \left(\frac{m}{2\pi k T}\right)^{1/2} \int_{-\infty}^{\infty} v_z \exp\left(-\frac{m v_z^2}{2 k T}\right) \dd{v_z}
\end{equation}
But we only care about the velocity in the positive direction, so this becomes:
\begin{equation}
\langle v_{z+} \rangle = \left(\frac{m}{2\pi k T}\right)^{1/2} \int_{0}^{\infty} v_z \exp\left(-\frac{m v_z^2}{2 k T}\right) \dd{v_z}
\end{equation}
\begin{equation}
  \langle v_{z+} \rangle = \frac{\sqrt{2kT}}{2 \sqrt{\pi m}}
\end{equation}
% Inline Python code in the document
\begin{lstlisting}[language=Python]
from sympy import *

# Define symbols for this \langle v_{z+} \rangle = \left(\frac{m}{2\pi k T}\right)^{1/2} \int_{0}^{\infty} v_z \exp\left(-\frac{m v_z^2}{2 k T}\right) \dd{v_z}
m, T, k = symbols('m T k', real=True, positive=True)
v_z = symbols('v_z', real=True)

# Define the integrand
integrand = v_z * exp(-m * v_z**2 / (2 * k * T))

# Compute the integral
integral = integrate(integrand, (v_z, 0, oo))

# Simplify the result
integral = simplify(integral)

# multiply by the prefactor
integral = sqrt(m / (2 * pi * k * T)) * integral

# simplify the result
integral = simplify(integral)

# Print the result
print(latex(integral)) 
\end{lstlisting}
The total flux $j$ is given by:
\begin{equation}
j = \rho \langle v_{z+} \rangle
\end{equation}
From the ideal gas law, we get that $\rho = \frac{p}{kT}$, so the flux is:
\begin{equation}
j = \frac{p}{kT} \frac{\sqrt{2kT}}{2 \sqrt{\pi m}}
\end{equation}
\subsection{}
(ii) (10 points) If a fraction $\phi$ of these molecules are bounced back, find the rate of evaporation of the liquid, i.e., the number of molecules that evaporate from the liquid per unit area per unit time.\\
For computing the rat of evaporation, we want to instead consider the compliment of the fraction of molecules bouncing back, or $1-\phi$. So the rate of evaporation is:
\begin{equation}
j_{\text{evap}} = j \cdot (1-\phi) = \frac{p}{kT} \frac{\sqrt{2kT}}{2 \sqrt{\pi m}} \cdot (1-\phi)
\end{equation}
\section{}
\begin{enumerate}
  \setcounter{enumi}{1}
  \item (20 points) Derive the adsorption isotherm for a 2-component ideal gas containing species $A$ and $B$. Assume that each adsorption site can only be singly occupied. The adsorption energy for species $A$ is $-\varepsilon_{A}$ and that for species $B$ is $-\varepsilon_{B}$. Express your result in terms of the partial pressures of each component.
\subsection{}
The grand canonical partition function is given by 
\begin{equation}
\Xi\left(N, T, \mu_A, \mu_B\right)=\sum_{N_A=0}^N \sum_{N_B=0}^{N-N_A}\left(\begin{array}{c}
N \\
N_A
\end{array}\right)\left(\begin{array}{c}
N-N_A \\
N_B
\end{array}\right) e^{\beta N_A\left(\mu_A+\epsilon_A\right)} e^{\beta N_B\left(\mu_B+\epsilon_B\right)}
\end{equation}
We will attempt to explain this form. The first submission is over the first species and it runs from 0 to the total particle number. The second submission is similar and it runs from 0 to the number of particles left after the first selection. The first binomial coefficient represents the number of ways to choose $N_A$ particles from the total number of particles. The second binomial coefficient represents the number of ways to choose $N_B$ particles from the remaining number of particles after the first selection. The first exponential term represents the energy and chemical potential contribution from the first species and the second exponential term represents the energy and chemical potential contribution from the second species. We can use the multinomial theorem to simplify this expression:
\begin{equation}
\Xi\left(N, T, \mu_A, \mu_B\right)=(1+e^{\beta\left(\mu_A+\epsilon_A\right)}+e^{\beta\left(\mu_B+\epsilon_B\right)})^N
\end{equation}
The fraction of sites occupied by species $A$ is $\Theta _{A} = \frac{\langle N_A \rangle}{N}$ and the fraction of sites occupied by species $B$ is $\Theta _{B} = \frac{\langle N_B \rangle}{N}$. We want to find $\langle N_A \rangle$ and $\langle N_B \rangle$. We know that the grand potential is given by:
\begin{equation}
\Omega = -kT \ln \Xi
\end{equation}
and then also the differential of the grand potential is given by:
\begin{equation}
\dd{\Omega} = -S \dd{T} - P \dd{V} - \sum_i \mu_i \dd{N_i} = -S \dd{T} - P \dd{V} - N_A \dd{\mu_A} - N_B \dd{\mu_B}
\end{equation}
So the expectation value of the particle number of the first species is given by:
\begin{equation}
\langle N_A \rangle = -\left(\frac{\partial \Omega}{\partial \mu_A}\right)_{T, V, \mu_B} = \left( \frac{\partial \ln \Xi}{\partial \beta \mu_A}\right)_{T, V, \mu_B}
\end{equation}
So, using this algorithm, we can get $\Theta _{A}$ and $\Theta _{B}$.
\begin{equation}
\Theta_A=\frac{\exp \left(\frac{\epsilon_A+\mu_A}{k T}\right)}{\exp \left(\frac{\epsilon_A+\mu_A}{k T}\right)+\exp \left(\frac{\epsilon_B+\mu_B}{k T}\right)+1}
\end{equation}
\begin{equation}
\Theta_B=\frac{\exp \left(\frac{\epsilon_B+\mu_B}{k T}\right)}{\exp \left(\frac{\epsilon_A+\mu_A}{k T}\right)+\exp \left(\frac{\epsilon_B+\mu_B}{k T}\right)+1}
\end{equation}
% Inline Python code in the document
\begin{lstlisting}[language=Python]
from sympy import symbols, exp, diff, solve, ln, simplify

# Define symbols
N, T, beta, mu_A, mu_B, epsilon_A, epsilon_B = symbols('N T beta mu_A mu_B epsilon_A epsilon_B')
N_A, N_B = symbols('N_A N_B')
k = symbols('k')

# Define the grand canonical partition function simplified expression
Xi = (1 + exp(beta*(mu_A + epsilon_A)) + exp(beta*(mu_B + epsilon_B)))**N

# Calculate the grand potential Omega
Omega = -k*T*ln(Xi)

# Calculate the expectation value of N_A and N_B
dOmega_dmuA = diff(Omega, mu_A)
dOmega_dmuB = diff(Omega, mu_B)

# Solve for <N_A> and <N_B>
N_A_avg = -dOmega_dmuA
N_B_avg = -dOmega_dmuB

# Calculate the fraction of sites occupied by species A and B
Theta_A = N_A_avg / N
Theta_B = N_B_avg / N

simplify(N_A_avg), simplify(N_B_avg), simplify(Theta_A), simplify(Theta_B)

\end{lstlisting}
We have $\theta_A\left(T, \epsilon_A, \epsilon_B, \mu_A, \mu_B\right)$ and we want to go to $\theta_A\left(T, \epsilon_A, \epsilon_B, P_A, P_B\right)$. We can use the equality of the chemical potentials in adsorption:
\begin{equation}
\beta \mu_A^{\text {ads }}=\beta \mu_A^{\text {free }}=\rho_A \Lambda_A^3
\end{equation}
And from that ideal gas law, we know that $\rho_A = \frac{P_A}{kT}$, so we can write:
\begin{equation}
\beta \mu_A^{\text {ads }}=\frac{P_A \Lambda_A^3}{kT}
\end{equation}
and for the second species:
\begin{equation}
\beta \mu_B^{\text {ads }}=\frac{P_B \Lambda_B^3}{kT}
\end{equation}
Substituting these into the expression for $\Theta_A$ and $\Theta_B$and simplifying::
\begin{equation}
\Theta_A = \frac{\Lambda_A^3 P_A \exp\left(\frac{\epsilon_A}{T k}\right)}{\Lambda_A^3 P_A \exp\left(\frac{\epsilon_A}{T k}\right) + \Lambda_B^3 P_B \exp\left(\frac{\epsilon_B}{T k}\right) + T k}
\end{equation}
\begin{equation}
\Theta_B = \frac{\Lambda_B^3 P_B \exp\left(\frac{\epsilon_B}{T k}\right)}{\Lambda_A^3 P_A \exp\left(\frac{\epsilon_A}{T k}\right) + \Lambda_B^3 P_B \exp\left(\frac{\epsilon_B}{T k}\right) + T k}
\end{equation}
% Inline Python code in the document
\begin{lstlisting}[language=Python]
# Define new symbols for partial pressures P_A and P_B, and thermal de Broglie wavelengths Lambda_A and Lambda_B
P_A, P_B, Lambda_A, Lambda_B = symbols('P_A P_B Lambda_A Lambda_B')

# Replace beta * mu_A and beta * mu_B in the expressions for Theta_A and Theta_B
Theta_A_expr = exp((epsilon_A + k*T*ln(P_A * Lambda_A**3 / (k*T)))/(k*T)) / \
               (exp((epsilon_A + k*T*ln(P_A * Lambda_A**3 / (k*T)))/(k*T)) + 
                exp((epsilon_B + k*T*ln(P_B * Lambda_B**3 / (k*T)))/(k*T)) + 1)

Theta_B_expr = exp((epsilon_B + k*T*ln(P_B * Lambda_B**3 / (k*T)))/(k*T)) / \
               (exp((epsilon_A + k*T*ln(P_A * Lambda_A**3 / (k*T)))/(k*T)) + 
                exp((epsilon_B + k*T*ln(P_B * Lambda_B**3 / (k*T)))/(k*T)) + 1)

simplify(Theta_A_expr), simplify(Theta_B_expr)
\end{lstlisting}
\section{}
  \item For the noninteracting Ising model, the joint probability for the system factorizes into a product of the probability for each spin, i.e., $P(\{s\})=\prod_{i} p_{i}\left(s_{i}\right)$.

\end{enumerate}
\subsection{}
(i) (5 points) Show that the Gibbs entropy is now


\begin{equation*}
S=-k \sum_{i} \sum_{s_{i}} p_{i}\left(s_{i}\right) \ln p_{i}\left(s_{i}\right) \tag{1}
\end{equation*}
The expression for the Gibbs entropy is given by:
\begin{equation}
S=-k \sum_{[s] } P(\{s\}) \ln P(\{s\})
\end{equation}
where $[s]$ denotes the set of all possible spin configurations and $P(\{s\})$ is the probability of the system being in the configuration $\{s\}$.
We insert the probability distribution given above into this expression:
\begin{equation}
S=-k \sum_{[s] } \prod_{i} p_{i}\left(s_{i}\right) \ln \prod_{i} p_{i}\left(s_{i}\right)
\end{equation}
We can use the fact that the logarithm of a product is the sum of the logarithms of the factors:
\begin{equation}
S=-k \sum_{[s] } \sum_{i} \ln p_{i}\left(s_{i}\right) \prod_{j} p_{j}\left(s_{j}\right)
\end{equation}
Now we take out the $i$th term from the product over $j$:
\begin{equation}
S=-k \sum_{[s] } (\sum_{i} p_{i}\left(s_{i}\right)\ln p_{i}\left(s_{i}\right)) \prod_{j\neq i} p_{j}\left(s_{j}\right)
\end{equation}
Now we know that we can decompose the sum overall possible spin configurations into a sum over the individual spins at a given site:
\begin{equation}
S=-k \sum_{s_1} \sum_{s_2} \ldots \sum_{s_i} \ldots \sum_{s_N} (\sum_{i} p_{i}\left(s_{i}\right)\ln p_{i}\left(s_{i}\right)) \prod_{j\neq i} p_{j}\left(s_{j}\right) 
\end{equation}
Merely rearranging, we get:
\begin{equation}
S=-k \sum_{s_1} \sum_{s_2} \ldots \sum_{s_N} (\sum_{s_i} \sum_{i} p_{i}\left(s_{i}\right)\ln p_{i}\left(s_{i}\right)) \prod_{j\neq i} p_{j}\left(s_{j}\right) 
\end{equation}
Now we want to prove that the residual is just equal to 1:
\begin{equation}
\sum_{s_1} \sum_{s_2} \ldots \ldots \sum_{s_N} \prod_{j\neq i} p_{j}\left(s_{j}\right)  
\end{equation}
Inserting each probability in the product into each of its summation, we see:
\begin{equation}
=\sum_{s_1} p_{1}\left(s_{1}\right) \sum_{s_2} p_{2}\left(s_{2}\right) \ldots \sum_{s_i} p_{i}\left(s_{i}\right) \ldots \sum_{s_N} p_{N}\left(s_{N}\right)
\end{equation}
But we know that the sum of probabilities for a given state has to be 1, so this is trust 1. So we get:
\begin{equation}
S=-k \sum_{i} \sum_{s_{i}} p_{i}\left(s_{i}\right) \ln p_{i}\left(s_{i}\right)
\end{equation}

\subsection{}
(ii) (5 points) Introducing the order parameter (average spin) $m_{i}=\left\langle s_{i}\right\rangle$, show that the variational free energy is


\begin{equation*}
G=-\sum_{i} h_{i} m_{i}+k T \sum_{i}\left(\frac{1+m_{i}}{2} \ln \frac{1+m_{i}}{2}+\frac{1-m_{i}}{2} \ln \frac{1-m_{i}}{2}\right) \tag{2}
\end{equation*}
The free energy is given by:
\begin{equation}
G=E-TS
\end{equation}
where $E$ is the energy of the system and $S$ is the entropy. We found the energy of the system in the lecture and it is given by:
\begin{equation}
\langle E\rangle=-\sum_i h_i\left\langle s_i\right\rangle=-\sum_i \sum_{s_i} h_i s_i p_i\left(s_i\right)
\end{equation}
So using our previously derived expression for the entropy, we can plug in to the above equation for the free energy:
\begin{equation}
G=-\sum_i \sum_{s_i} h_i s_i p_i\left(s_i\right)+kT\sum_i \sum_{s_i} p_i\left(s_i\right) \ln p_i\left(s_i\right)
\end{equation}
But we know that the sum of the probabilities that a given state has a spin pointing up or down has to be 1: $p_i\left(s_i=1\right)+p_i\left(s_i=-1\right)=1$. Also, from the definition of the magnetization we know that $m_i=\left\langle s_i\right\rangle=p_i\left(s_i=1\right)-p_i\left(s_i=-1\right)$. So we can write the spin probability in terms of the magnetization as:
\begin{equation}
p_i\left(s_i=\pm1\right)=\frac{1\pm m_i}{2}
\end{equation}
We can use this to get read of the sum over the individual spins at a given site and rewrite this in terms of the magnetization:
\begin{equation}
G=-\sum_i h_i m_i+kT\sum_i \left(\frac{1+m_i}{2} \ln \frac{1+m_i}{2}+\frac{1-m_i}{2} \ln \frac{1-m_i}{2}\right)
\end{equation}
\subsection{}

(iii) (10 points) Show that minimization of this free energy yields the same equation of state as obtained in class by directly working with the partition function. Also show that the minimized free energy is the same as obtained in class using the partition function.\\
We want to minimize the previous expression for the free energy with respect to the magnetization at a given state:
\begin{equation}
\frac{\partial G}{\partial m_i}=0
\end{equation}
Taking the first derivative of the above expression for the free energy. The first term will vanish unless the magnetization of the state we are taking the derivative with respect two is the same as the magnetization within the summation, so it simplifies to one turn of the sum:
\begin{equation}
\frac{\partial (-\sum_i h_i m_i)}{\partial m_i}=-h_i
\end{equation}
For the second term the summation will vanish for the same reason as before, so we get for all of this:
\begin{equation}
\frac{\partial G}{\partial m_i}=-T \cdot k \cdot\left(-\frac{1}{2} \log \left(\frac{1}{2}-\frac{m_i}{2}\right)+\frac{1}{2} \log \left(\frac{m_i}{2}+\frac{1}{2}\right)\right)-h_i
\end{equation}
% Inline Python code in the document
\begin{lstlisting}[language=Python]
# Correct the free energy equation G by removing the incorrect sum usage
G = -hi * mi - k * T * ((1 + mi) / 2 * ln((1 + mi) / 2) + (1 - mi) / 2 * ln((1 - mi) / 2))

# Compute the first derivative of G with respect to mi correctly
dG_dmi_correct = diff(G, mi)

dG_dmi_correct
\end{lstlisting}
Now, we said this equal to 0 and solve for $m_i$:
\begin{equation}
m_i=-\tanh \left(\frac{\log \left(\exp \left(2 h_i\right)\right)}{2 T k}\right) = \tanh \left(\beta h_i\right)
\end{equation}
% Inline Python code in the document
\begin{lstlisting}[language=Python]
from sympy import solve, log

# Set the derivative equal to zero and solve for mi
solution = solve(dG_dmi_correct, mi)

solution
\end{lstlisting}
Now, that we have found this equation of state, we want to plug it for $m_i$ into our expression for the variational free energy. 
\begin{equation}
G=-\sum_i h_i \tanh \left(\beta h_i\right)+kT\sum_i\left(\frac{1+\tanh \left(\beta h_i\right)}{2} \ln \frac{1+\tanh \left(\beta h_i\right)}{2}+\frac{1-\tanh \left(\beta h_i\right)}{2} \ln \frac{1-\tanh \left(\beta h_i\right)}{2}\right)
\end{equation}
We just consider the second submission for now and we factor out the prefacors at the front of the logarithms:
\begin{equation}
\frac{1}{2} \ln \frac{1+\tanh \left(\beta h_i\right)}{2}+\frac{\tanh \left(\beta h_i\right)}{2} \ln \frac{1+\tanh \left(\beta h_i\right)}{2}+\frac{1}{2} \ln \frac{1-\tanh \left(\beta h_i\right)}{2}-\frac{\tanh \left(\beta h_i\right)}{2} \ln \frac{1-\tanh \left(\beta h_i\right)}{2}
\end{equation}
We have like terms that we can group into just two logarithms together:
\begin{equation}
\frac{1}{2} \ln \left(\frac{1+\tanh \left(\beta h_i\right)}{2}\cdot\frac{1-\tanh \left(\beta h_i\right)}{2}\right)+ \frac{\tanh \left(\beta h_i\right)}{2} \ln \left(\frac{1+\tanh \left(\beta h_i\right)}{1-\tanh \left(\beta h_i\right)}\right)
\end{equation}
Now we can use the definition of the hepatic tangent in terms of exponentials $\tanh \left(\beta h_i\right)=\frac{\exp \left(\beta h_i\right)-\exp \left(-\beta h_i\right)}{\exp \left(\beta h_i\right)+\exp \left(-\beta h_i\right)}$:
\begin{equation}
\frac{1}{2} \ln \left(\frac{1-\tanh^2 \left(\beta h_i\right)}{4}\right)+ \frac{\tanh \left(\beta h_i\right)}{2} \ln \left(\frac{\exp \left(2\beta h_i\right)+1}{\exp \left(2\beta h_i\right)-1}\right)
\end{equation}
For the first term, we recognize that $1-\tanh^2 \left(\beta h_i\right)=\sech^2 \left(\beta h_i\right)$, so we can write:
\begin{equation}
\frac{1}{2} \ln \left(\frac{\sech^2 \left(\beta h_i\right)}{4}\right)+ \frac{\tanh \left(\beta h_i\right)}{2} \ln \left(\frac{\exp \left(2\beta h_i\right)+1}{\exp \left(2\beta h_i\right)-1}\right)
\end{equation}
For the first term, we can also take out a square factor from the logo rhythm to cancel out the constant and front:
\begin{equation}
\ln \left(\frac{\sech \left(\beta h_i\right)}{2}\right)+ \frac{\tanh \left(\beta h_i\right)}{2} \ln \left(\frac{\exp \left(2\beta h_i\right)+1}{\exp \left(2\beta h_i\right)-1}\right)
\end{equation}
Now the definition of the hypergolic secant in terms of exponentials is $\sech \left(\beta h_i\right)=\frac{2}{\exp \left(\beta h_i\right)+\exp \left(-\beta h_i\right)}$, so we can write:
\begin{equation}
\ln \left(\frac{1}{\exp \left(\beta h_i\right)+\exp \left(-\beta h_i\right)}\right)+ \frac{\tanh \left(\beta h_i\right)}{2} \ln \left(\frac{\exp \left(2\beta h_i\right)+1}{\exp \left(2\beta h_i\right)-1}\right)
\end{equation}
I am not sure where to go from here.1 


\section{}
\begin{enumerate}
  \setcounter{enumi}{3}
  \item For the 1-dimensional Ising model with periodic boundary condition, the Hamiltonian is given by
\end{enumerate}


\begin{equation*}
H=-K\left(s_{1} s_{2}+s_{2} s_{3}+\cdots+s_{N} s_{1}\right)-h \sum_{i=1}^{N} s_{i} \tag{3}
\end{equation*}


Use the transfer matrix method to obtain an exact solution in the limit of large $N$. In particular,
\subsection{}
(i) (10 points) Show that the partition function is given by


\begin{equation*}
Z=\operatorname{Tr}\left(\mathbf{T}^{N}\right)=\lambda_{+}^{N}+\lambda_{-}^{N} \approx \lambda_{+}^{N} \tag{4}
\end{equation*}


with the transfer matrix

\[
\mathbf{T}=\left(\begin{array}{cc}
\mathrm{e}^{\beta K+\beta h} & \mathrm{e}^{-\beta K}  \tag{5}\\
\mathrm{e}^{-\beta K} & \mathrm{e}^{\beta K-\beta h}
\end{array}\right)
\]

and $\lambda_{+}$the larger of the two eigenvalues of the transfer matrix, $\lambda_{+}$and $\lambda_{-}$.\\
Our first step will be to derive the form of this transfer matrix. Given this form of the antonian, we know the partition function is given by:
\begin{equation}
Z = \sum_{s_{1} = \pm 1} \sum_{s_{2} = \pm 1} \ldots \sum_{s_{N} = \pm 1} e^{K\beta s_{1}s_{2}+\frac{1}{2}h\beta\left(s_{1}+s_{2}\right)} e^{K\beta s_{2}s_{3}+\frac{1}{2}h\beta\left(s_{2}+s_{3}\right)} \ldots e^{K\beta s_{N}s_{1}+\frac{1}{2}h\beta\left(s_{N}+s_{1}\right)}
\end{equation}
By introducing theorthonormal bases of $\ket{+}= \begin{pmatrix} 1 \\ 0 \end{pmatrix}$ and $\ket{-}= \begin{pmatrix} 0 \\ 1 \end{pmatrix}$ with the identity operator given by $\textbf{I} = \ket{+}\bra{+} + \ket{-}\bra{-}$, we can write a certain term in the partition function as an element of the transfer matrix as:
\begin{equation}
e^{K\beta s_{i}s_{i+1}+\frac{1}{2}h\beta\left(s_{i}+s_{i+1}\right)} = \bra{s_i}\textbf{T}\ket{s_{i+1}}
\end{equation}
One can extrapolate how the transfer matrix is constructed from this.
We started by diagnosing the transfer matrix, which gives the Iran values:
\begin{equation}
  \lambda_{+} = \frac{\sqrt{\left(e^{\beta(K - h)} + e^{\beta(K + h)}\right)^2 - 8\sinh(2K\beta)}}{2} + \frac{e^{\beta(K - h)}}{2} + \frac{e^{\beta(K + h)}}{2}
\end{equation}
and
\begin{equation}
  \lambda_{-} = -\frac{\sqrt{\left(e^{\beta(K - h)} + e^{\beta(K + h)}\right)^2 - 8\sinh(2K\beta)}}{2} + \frac{e^{\beta(K - h)}}{2} + \frac{e^{\beta(K + h)}}{2}
\end{equation}
% Inline Python code in the document
\begin{lstlisting}[language=Python]
from sympy import Matrix, symbols, exp, simplify

# Define symbols
beta, K, h = symbols('beta K h')

# Define the transfer matrix T
T = Matrix([[exp(beta * K + beta * h), exp(-beta * K)],
            [exp(-beta * K), exp(beta * K - beta * h)]])

# Diagonalize the transfer matrix T
eigenvals = T.eigenvals()
eigenvals_simplified = [simplify(val) for val in eigenvals.keys()]

# Since the user asked for the larger eigenvalue, let's identify it
lambda_plus = max(eigenvals_simplified, key=lambda x: x.subs({beta: 1, K: 1, h: 1}))
lambda_minus = min(eigenvals_simplified, key=lambda x: x.subs({beta: 1, K: 1, h: 1}))

lambda_plus, lambda_minus
\end{lstlisting}
This will allow us to affectionately take the power of the matrix since if it were not diagonal, this would be nonsensical. Now in diagonal form this matrix is:
\begin{equation}
\mathbf{T}=\left(\begin{array}{cc}
\lambda_{+} & 0 \\
0 & \lambda_{-}
\end{array}\right)
\end{equation}
If we take the cancer matrix to the power of $N$ we get:
\begin{equation}
\mathbf{T}^N=\left(\begin{array}{cc}
\lambda_{+}^N & 0 \\
0 & \lambda_{-}^N
\end{array}\right)
\end{equation}
So the trace of this matrix is:
\begin{equation}
\operatorname{Tr}\left(\mathbf{T}^{N}\right)=\lambda_{+}^{N}+\lambda_{-}^{N}
\end{equation}
Because $\lambda_{+}$ is even slightly larger than $\lambda_{-}$, in the thermo dynamic limit with a large $N$, we can approximate:
\begin{equation}
\operatorname{Tr}\left(\mathbf{T}^{N}\right)\approx\lambda_{+}^{N}
\end{equation}
\subsection{}

(ii) (10 points) Show that the eigenvalues are


\begin{equation*}
\lambda_{ \pm}=\mathrm{e}^{\beta K} \cosh (\beta h) \pm \sqrt{\mathrm{e}^{2 \beta K} \sinh ^{2}(\beta h)+\mathrm{e}^{-2 \beta K}} \tag{6}
\end{equation*}
We found the the again values from the symbol diagonalization of the transfer matrix:
\begin{equation}
  \lambda_{+} = \frac{\sqrt{\left(e^{\beta(K - h)} + e^{\beta(K + h)}\right)^2 - 8\sinh(2K\beta)}}{2} + \frac{e^{\beta(K - h)}}{2} + \frac{e^{\beta(K + h)}}{2}
\end{equation}
and
\begin{equation}
  \lambda_{-} = -\frac{\sqrt{\left(e^{\beta(K - h)} + e^{\beta(K + h)}\right)^2 - 8\sinh(2K\beta)}}{2} + \frac{e^{\beta(K - h)}}{2} + \frac{e^{\beta(K + h)}}{2}
\end{equation}
For the term outside of the square root we can take out a common factor of $e^{\beta K}$ and use the identity $\cosh(\beta h) = \frac{e^{\beta h} + e^{-\beta h}}{2}$ to simplify the expression:
\begin{equation}
\lambda_{ \pm}=\mathrm{e}^{\beta K} \cosh (\beta h) \pm \frac{\sqrt{\left(e^{\beta(K - h)} + e^{\beta(K + h)}\right)^2 - 8\sinh(2K\beta)}}{2}
\end{equation}
\subsection{}
(iii) (10 points) Examine and comment on the behavior of entropy and energy at $T=0$ and $T=\infty$.
Since we know the partition function, the expression for the energy is:
\begin{equation}
\langle E\rangle=-\frac{\partial \ln Z}{\partial \beta}
\end{equation}
We start by considering $\ln Z$:
\begin{equation}
\ln Z = N \ln \lambda_{+}
\end{equation}
We know that in the large beta limit the positive eigenvalue is:
\begin{equation}
\lambda_{+}=\mathrm{e}^{\beta K} \cosh (\beta h) + \sqrt{\mathrm{e}^{2 \beta K} \sinh ^{2}(\beta h)+\mathrm{e}^{-2 \beta K}} \rightarrow \mathrm{e}^{\beta K} \cosh (\beta h) + \mathrm{e}^{\beta K} \sinh (\beta h)
\end{equation}
Factoring out the common factor of $\mathrm{e}^{\beta K}$ and using the identity $\cosh(\beta h) = \frac{e^{\beta h} + e^{-\beta h}}{2}$ and $\sinh(\beta h) = \frac{e^{\beta h} - e^{-\beta h}}{2}$, we get:
\begin{equation}
\lambda_{+} \rightarrow \mathrm{e}^{\beta K} \left(\cosh (\beta h) + \sinh (\beta h)\right) = \mathrm{e}^{\beta K} \exp(\beta h)
\end{equation}
So, the logarithm of the partition function gives:
\begin{equation}
\ln Z \rightarrow N \left(\beta K + \beta h\right)
\end{equation}
So, the energy is given by:
\begin{equation}
\langle E\rangle=-\frac{\partial \ln Z}{\partial \beta}=-N\left(K+h\right)
\end{equation}
Next, we consider the limit of small beta. In this limit, the positive eigenvalue is:
\begin{equation}
\lambda_{+}=\mathrm{e}^{\beta K} \cosh (\beta h) + \sqrt{\mathrm{e}^{2 \beta K} \sinh ^{2}(\beta h)+\mathrm{e}^{-2 \beta K}} \rightarrow \mathrm{e}^{\beta K} + e^{-\beta K}
\end{equation}
In this limit, this simply gives 2. So, the logarithm of the partition function gives:
\begin{equation}
\ln Z \rightarrow N \ln 2
\end{equation}
So, the energy is given by:
\begin{equation}
\langle E\rangle=-\frac{\partial \ln Z}{\partial \beta}=0
\end{equation}
We know that:
\begin{equation}
S=k(\ln Z+\beta E)
\end{equation}
Saw, in the limit of high beta, we get:
\begin{equation}
S \rightarrow k(N \left(\beta K + \beta h\right) - \beta N \left(K+h\right)) = 0
\end{equation}
In the limit of small beta, we get:
\begin{equation}
S \rightarrow k(N \ln 2 + 0) = kN \ln 2
\end{equation}
(iv) (Bonus 15 points) Show that the spin-spin correlation function at zero external field is given by


\begin{equation*}
\left\langle s_{i} s_{i+r}\right\rangle=\frac{\lambda_{+}^{N-r} \lambda_{-}^{r}+\lambda_{-}^{N-r} \lambda_{+}^{r}}{\lambda_{+}^{N}+\lambda_{-}^{N}} \approx\left(\frac{\lambda_{-}}{\lambda_{+}}\right)^{r} \equiv \mathrm{e}^{-r / \xi} \tag{7}
\end{equation*}


with the correlation length


\begin{equation*}
\xi=\left[\ln \left(\frac{\lambda_{+}}{\lambda_{-}}\right)\right]^{-1}=-\frac{1}{\ln \tanh (\beta K)} \tag{8}
\end{equation*}


For Problem 4, you may consult any reference materials, including books and online resources. However, the work you write down must reflect your own understanding.


\end{document}